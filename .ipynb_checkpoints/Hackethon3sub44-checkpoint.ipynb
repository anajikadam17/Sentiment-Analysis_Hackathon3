{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from time import time\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import emoji\n",
    "from pprint import pprint\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "from sklearn.metrics import roc_auc_score ,mean_squared_error,accuracy_score,classification_report,confusion_matrix,roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.externals import joblib\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading the Train data\n",
    "def load_train():\n",
    "    df = pd.read_csv('data/train.csv')\n",
    "    df = df[['tweet', 'sentiment']]\n",
    "    df = df.dropna()\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "# df = load_train()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading the Train data\n",
    "def load_test():\n",
    "    df = pd.read_csv('data/test.csv')\n",
    "    df = df[['tweet_id','tweet']]\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "# dftest = load_test()\n",
    "# df1 = dftest[['tweet']]\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d0dde21cfa63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mtc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextCounts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0mdf_eda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[0mdf_eda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "class TextCounts(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def count_regex(self, pattern, tweet):\n",
    "        return len(re.findall(pattern, tweet))\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # fit method is used when specific operations need to be done on the train data, but not on the test data\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        def has_long(sentence):\n",
    "            a = []\n",
    "            for x in sentence.split():\n",
    "                if re.compile(\"([a-zA-Z])\\\\1{2,}\").search(x):\n",
    "                    a.append(x)\n",
    "            return a\n",
    "        def isalpha(stre):\n",
    "            countl=0\n",
    "            for i in stre:\n",
    "                if i.isalpha():\n",
    "                    countl+=1\n",
    "            return countl\n",
    "        def isdig(stre):\n",
    "            countn=0\n",
    "            for i in stre:\n",
    "                if i.isdigit():\n",
    "                    countn+=1\n",
    "            return countn\n",
    "        fstcap = X.apply(lambda a:[''.join(c) for c in a.strip().split() if c[0].isupper()]) # list of first capital letter\n",
    "        elgwrd = X.apply(lambda a:has_long(a)) # list of Elongated word\n",
    "        NofChr = X.apply(lambda a:isalpha(a)) # number of character\n",
    "        Nofdgt = X.apply(lambda a:isdig(a)) # number of digit\n",
    "        count_words = X.apply(lambda x: self.count_regex(r'\\w+', str(x)))   # count word \n",
    "        count_mentions = X.apply(lambda x: self.count_regex(r'@\\w+', str(x)))  # count mentions\n",
    "        count_hashtags = X.apply(lambda x: self.count_regex(r'#\\w+', str(x)))  # count hashtags\n",
    "        count_capital_words = X.apply(lambda x: self.count_regex(r'\\b[A-Z]{2,}\\b', str(x)))   # count uppercase words\n",
    "        count_excl_quest_marks = X.apply(lambda x: self.count_regex(r'!|\\?', str(x)))     # count exclametory mark\n",
    "        count_urls = X.apply(lambda x: self.count_regex(r'http.?://[^\\s]+[\\s]?', str(x)))  # count urls\n",
    "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
    "        # Moreover, it will result in having more words in the tweet\n",
    "        count_emojis = X.apply(lambda x: emoji.demojize(str(x))).apply(lambda x: self.count_regex(r':[a-z_&]+:', str(x)))\n",
    "        \n",
    "        df = pd.DataFrame({'count_words': count_words\n",
    "                           , 'count_char': NofChr\n",
    "                           , 'count_digit': Nofdgt\n",
    "                           , 'count_mentions': count_mentions\n",
    "                           , 'count_hashtags': count_hashtags\n",
    "                           , 'count_capital_words': count_capital_words\n",
    "                           , 'count_fCap': fstcap\n",
    "                           , 'count_Elgwords': elgwrd\n",
    "                           , 'count_excl_quest_marks': count_excl_quest_marks\n",
    "                           , 'count_urls': count_urls\n",
    "                           , 'count_emojis': count_emojis\n",
    "                          })\n",
    "        \n",
    "        return df\n",
    "tc = TextCounts()\n",
    "df_eda = tc.fit_transform(df.tweet)\n",
    "df_eda['sentiment'] = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', str(input_text))\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', str(input_text))\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)\n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', str(input_text))\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def stemming(self, input_text):\n",
    "        porter = PorterStemmer()\n",
    "        words = input_text.split() \n",
    "        stemmed_words = [porter.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords).apply(self.stemming)\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is: 0.652233676975945\n",
      "1    1445\n",
      "2    370 \n",
      "0    4   \n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = load_train()  # load train data\n",
    "df1 = load_test() # load test data\n",
    "\n",
    "# create numerical feature for train\n",
    "tc = TextCounts()\n",
    "df_train = tc.fit_transform(df.tweet)\n",
    "df_train['sentiment'] = df.sentiment\n",
    "# create numerical feature for test\n",
    "df_test = tc.fit_transform(df1['tweet'])\n",
    "# clean text for train and CountVectorizer train data\n",
    "ct = CleanText()\n",
    "train_clean = ct.fit_transform(df['tweet'])\n",
    "# clean text for test and CountVectorizer test data\n",
    "ct = CleanText()\n",
    "test_clean = ct.fit_transform(df1['tweet'])\n",
    "\n",
    "df_model = df_train\n",
    "df_model['clean_text'] = train_clean\n",
    "df1_model = df_test\n",
    "df1_model['clean_text'] = test_clean\n",
    "\n",
    "X = df_model['clean_text']\n",
    "X1 = df1_model['clean_text']\n",
    "y = df_model.sentiment\n",
    "Hv = HashingVectorizer(stop_words = 'english')       # HashinhVectorizer\n",
    "Xh = Hv.fit_transform(X)\n",
    "\n",
    "df_test = df1_model['clean_text']\n",
    "df_test1 = Hv.transform(df_test)\n",
    "\n",
    "def LogReg(X,y):\n",
    "    global model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_score = model.predict(X_test)\n",
    "#     print('Train Accuracy:\\n',model.score(X_train,y_train))\n",
    "#     print('Validation Accuracy:\\n',model.score(X_test,y_test))\n",
    "#     print('Classification Report:\\n',classification_report(y_test, y_score))\n",
    "#     print(\"Precision Score : \",precision_score(y_test, y_score,average='micro'))\n",
    "#     print(\"Recall Score : \",recall_score(y_test, y_score,average='micro'))\n",
    "    # calculating the f1 score for the validation set\n",
    "    f1 = f1_score(y_test, y_score,average='micro')\n",
    "    \n",
    "    return f1\n",
    "\n",
    "#trainning\n",
    "X = Xh\n",
    "y = df_model.sentiment\n",
    "f1 = LogReg(X,y)    \n",
    "print('f1 score is:',f1)\n",
    "\n",
    "#testing function\n",
    "def prediction(test):\n",
    "    y_pred = model.predict(test)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "# Storing the Id column\n",
    "Id = df1[['tweet_id']]\n",
    "\n",
    "#predicting on test file\n",
    "y_pred = pd.DataFrame(prediction(df_test1),columns=['sentiment']) \n",
    "print(y_pred['sentiment'].value_counts())\n",
    "submission = pd.concat([Id,y_pred['sentiment']],1)\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sxswnui sxsw appl defin languag touch differ dialect becom smaller</td>\n",
       "      <td>1</td>\n",
       "      <td>sxswnui sxsw appl defin languag touch differ dialect becom smaller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learn ab googl doodl doodl light funni amp innov except signific occas googledoodl sxsw</td>\n",
       "      <td>1</td>\n",
       "      <td>learn ab googl doodl doodl light funni amp innov except signif occa googledoodl sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one face ex steal show yr rt quot sxsw appl school mkt expert quot link</td>\n",
       "      <td>2</td>\n",
       "      <td>one face ex steal show yr rt quot sxsw appl school mkt expert quot link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iphon sxsw app would pretti awesom crash everi min extend brows fuckit illmakeitwork</td>\n",
       "      <td>0</td>\n",
       "      <td>iphon sxsw app would pretti awesom crash everi min extend brow fuckit illmakeitwork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>line outsid appl store austin wait new ipad sxsw link</td>\n",
       "      <td>1</td>\n",
       "      <td>line outsid appl store austin wait new ipad sxsw link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                clean_text  \\\n",
       "0  sxswnui sxsw appl defin languag touch differ dialect becom smaller                        \n",
       "1  learn ab googl doodl doodl light funni amp innov except signific occas googledoodl sxsw   \n",
       "2  one face ex steal show yr rt quot sxsw appl school mkt expert quot link                   \n",
       "3  iphon sxsw app would pretti awesom crash everi min extend brows fuckit illmakeitwork      \n",
       "4  line outsid appl store austin wait new ipad sxsw link                                     \n",
       "\n",
       "   sentiment  \\\n",
       "0  1           \n",
       "1  1           \n",
       "2  2           \n",
       "3  0           \n",
       "4  1           \n",
       "\n",
       "                                                                                  tweet  \n",
       "0  sxswnui sxsw appl defin languag touch differ dialect becom smaller                    \n",
       "1  learn ab googl doodl doodl light funni amp innov except signif occa googledoodl sxsw  \n",
       "2  one face ex steal show yr rt quot sxsw appl school mkt expert quot link               \n",
       "3  iphon sxsw app would pretti awesom crash everi min extend brow fuckit illmakeitwork   \n",
       "4  line outsid appl store austin wait new ipad sxsw link                                 "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "\n",
    "def load_train():\n",
    "    df = pd.read_csv('data/file.csv')\n",
    "    df = df[['clean_text', 'sentiment']] \n",
    "    df = df.dropna()\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "df_model = load_train()\n",
    "stop_words = list(set(stopwords.words('english')))+list(punctuation)+['``', \"'s\", \"...\", \"n't\", r'<.*?>','br']\n",
    "\n",
    "# tokenize\n",
    "df_model['tweet']  = [nltk.word_tokenize(x) for x in df_model['clean_text']]\n",
    "\n",
    "# stopword removal\n",
    "df_model['tweet'] = df_model['tweet'].apply(lambda row: [word for word in row if word not in stop_words])\n",
    "\n",
    "# stemming words\n",
    "stemmer = PorterStemmer()\n",
    "snow_stemmer = SnowballStemmer('english')\n",
    "df_model['tweet'] = df_model['tweet'].apply(lambda x: [snow_stemmer.stem(i) for i in x])\n",
    "df_model['tweet'] = df_model['tweet'].apply(lambda x: ' '.join(x))\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of features: 1048576\n"
     ]
    }
   ],
   "source": [
    "X = df_model['tweet']\n",
    "y = df_model['sentiment']\n",
    "\n",
    "Hv = HashingVectorizer(stop_words = 'english')\n",
    "Xh = Hv.fit_transform(X)\n",
    "print('No of features: {}'.format(Xh.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== SVC ==================================================\n",
      "Train Accuracy:\n",
      " 0.5931591612237882\n",
      "Validation Accuracy:\n",
      " 0.5903780068728522\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        84\n",
      "          1       0.59      1.00      0.74       859\n",
      "          2       0.00      0.00      0.00       485\n",
      "          3       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.35      0.59      0.44      1455\n",
      "\n",
      "Precision Score :  0.5903780068728522\n",
      "Recall Score :  0.5903780068728522\n",
      "F1 score : 0.5903780068728522\n",
      "========================================================================================================================\n",
      "Max f1_score is 0.5903780068728522 in model SVC\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "def run_model(predictors,target, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=6)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_scores = model.predict(X_test)\n",
    "    print('Train Accuracy:\\n',model.score(X_train,y_train))\n",
    "    print('Validation Accuracy:\\n',model.score(X_test,y_test))\n",
    "    print('Classification Report:\\n',classification_report(y_test, y_scores))\n",
    "    print(\"Precision Score : \",precision_score(y_test, y_scores,average='micro'))\n",
    "    print(\"Recall Score : \",recall_score(y_test, y_scores,average='micro'))\n",
    "\n",
    "    # calculating the f1 score for the validation set\n",
    "    print(\"F1 score :\", f1_score(y_test, y_scores,average='micro'))\n",
    "    f1.append(f1_score(y_test, y_scores,average='micro'))\n",
    "    print(\"=\"*120)\n",
    "#     a = max(f1)\n",
    "#     b = f1.index(min(f1))\n",
    "    return f1\n",
    "\n",
    "\n",
    "# Predictors\n",
    "X = Xh\n",
    "y = df_model['sentiment']\n",
    "\n",
    "# models = {'Logistic Regression':LogisticRegression()\n",
    "#           ,'Decision Tree':DecisionTreeClassifier()\n",
    "#           ,'Random Forest': RandomForestClassifier()\n",
    "#           ,'MNB':MultinomialNB()\n",
    "#           ,'SVC':SVC()}\n",
    "\n",
    "models = {'SVC':SVC()}\n",
    "\n",
    "j = 0\n",
    "for i in models.items():\n",
    "    print('='*50,list(models.keys())[j],'='*50)\n",
    "    model = i[1]\n",
    "    a = run_model(X, y, model)\n",
    "    j=j+1\n",
    "print('Max f1_score is {} in model {}'.format(max(a),list(models.keys())[a.index(max(a))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of features: 6345\n"
     ]
    }
   ],
   "source": [
    "X = df_model['tweet']\n",
    "y = df_model['sentiment']\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "Xt = tfidf.fit_transform(X)\n",
    "print('No of features: {}'.format(Xt.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== Logistic Regression ==================================================\n",
      "Train Accuracy:\n",
      " 0.7490546579580611\n",
      "Validation Accuracy:\n",
      " 0.6694158075601374\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.04      0.07        84\n",
      "          1       0.67      0.93      0.78       859\n",
      "          2       0.66      0.36      0.47       485\n",
      "          3       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.65      0.67      0.62      1455\n",
      "\n",
      "Precision Score :  0.6694158075601374\n",
      "Recall Score :  0.6694158075601374\n",
      "F1 score : 0.6694158075601374\n",
      "========================================================================================================================\n",
      "================================================== Decision Tree ==================================================\n",
      "Train Accuracy:\n",
      " 0.9920935029219663\n",
      "Validation Accuracy:\n",
      " 0.6048109965635738\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.23      0.25        84\n",
      "          1       0.69      0.74      0.71       859\n",
      "          2       0.51      0.46      0.48       485\n",
      "          3       0.05      0.04      0.04        27\n",
      "\n",
      "avg / total       0.59      0.60      0.60      1455\n",
      "\n",
      "Precision Score :  0.6048109965635738\n",
      "Recall Score :  0.6048109965635738\n",
      "F1 score : 0.6048109965635738\n",
      "========================================================================================================================\n",
      "================================================== Random Forest ==================================================\n",
      "Train Accuracy:\n",
      " 0.9687177724303885\n",
      "Validation Accuracy:\n",
      " 0.6371134020618556\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.20      0.30        84\n",
      "          1       0.66      0.87      0.75       859\n",
      "          2       0.58      0.33      0.42       485\n",
      "          3       0.17      0.04      0.06        27\n",
      "\n",
      "avg / total       0.61      0.64      0.60      1455\n",
      "\n",
      "Precision Score :  0.6371134020618556\n",
      "Recall Score :  0.6371134020618556\n",
      "F1 score : 0.6371134020618556\n",
      "========================================================================================================================\n",
      "================================================== MNB ==================================================\n",
      "Train Accuracy:\n",
      " 0.7205225163286353\n",
      "Validation Accuracy:\n",
      " 0.6329896907216495\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.02        84\n",
      "          1       0.63      0.96      0.76       859\n",
      "          2       0.66      0.19      0.30       485\n",
      "          3       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.62      0.63      0.55      1455\n",
      "\n",
      "Precision Score :  0.6329896907216495\n",
      "Recall Score :  0.6329896907216495\n",
      "F1 score : 0.6329896907216495\n",
      "========================================================================================================================\n",
      "================================================== SVC ==================================================\n",
      "Train Accuracy:\n",
      " 0.8090409075283602\n",
      "Validation Accuracy:\n",
      " 0.6742268041237114\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.10      0.16        84\n",
      "          1       0.68      0.91      0.78       859\n",
      "          2       0.66      0.40      0.50       485\n",
      "          3       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.65      0.67      0.63      1455\n",
      "\n",
      "Precision Score :  0.6742268041237114\n",
      "Recall Score :  0.6742268041237114\n",
      "F1 score : 0.6742268041237114\n",
      "========================================================================================================================\n",
      "Max f1_score is 0.6742268041237114 in model SVC\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "def run_model(predictors,target, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=6)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_scores = model.predict(X_test)\n",
    "    print('Train Accuracy:\\n',model.score(X_train,y_train))\n",
    "    print('Validation Accuracy:\\n',model.score(X_test,y_test))\n",
    "    print('Classification Report:\\n',classification_report(y_test, y_scores))\n",
    "    print(\"Precision Score : \",precision_score(y_test, y_scores,average='micro'))\n",
    "    print(\"Recall Score : \",recall_score(y_test, y_scores,average='micro'))\n",
    "\n",
    "    # calculating the f1 score for the validation set\n",
    "    print(\"F1 score :\", f1_score(y_test, y_scores,average='micro'))\n",
    "    f1.append(f1_score(y_test, y_scores,average='micro'))\n",
    "    print(\"=\"*120)\n",
    "#     a = max(f1)\n",
    "#     b = f1.index(min(f1))\n",
    "    return f1\n",
    "\n",
    "\n",
    "# Predictors\n",
    "X = Xt\n",
    "y = df_model['sentiment']\n",
    "\n",
    "models = {'Logistic Regression':LogisticRegression()\n",
    "          ,'Decision Tree':DecisionTreeClassifier()\n",
    "          ,'Random Forest': RandomForestClassifier()\n",
    "          ,'MNB':MultinomialNB()\n",
    "          ,'SVC':SVC(kernel='linear', gamma = 6, random_state=0)}\n",
    "\n",
    "j = 0\n",
    "for i in models.items():\n",
    "    print('='*50,list(models.keys())[j],'='*50)\n",
    "    model = i[1]\n",
    "    a = run_model(X, y, model)\n",
    "    j=j+1\n",
    "print('Max f1_score is {} in model {}'.format(max(a),list(models.keys())[a.index(max(a))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is: 0.5725085910652921\n",
      "1    1637\n",
      "2    182 \n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def LogReg(X,y):\n",
    "    global model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6)\n",
    "    model = SVC()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_score = model.predict(X_test)\n",
    "#     print('Train Accuracy:\\n',model.score(X_train,y_train))\n",
    "#     print('Validation Accuracy:\\n',model.score(X_test,y_test))\n",
    "#     print('Classification Report:\\n',classification_report(y_test, y_score))\n",
    "#     print(\"Precision Score : \",precision_score(y_test, y_score,average='micro'))\n",
    "#     print(\"Recall Score : \",recall_score(y_test, y_score,average='micro'))\n",
    "    # calculating the f1 score for the validation set\n",
    "    f1 = f1_score(y_test, y_score,average='micro')\n",
    "    return f1\n",
    "\n",
    "#trainning\n",
    "X = df_model.drop(['sentiment','clean_text'], axis=1)\n",
    "y = df_model.sentiment\n",
    "f1 = LogReg(X,y)    \n",
    "print('f1 score is:',f1)\n",
    "\n",
    "#testing function\n",
    "def prediction(test):\n",
    "    y_pred = model.predict(test)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "# Storing the Id column\n",
    "Id = dftest[['tweet_id']]\n",
    "\n",
    "#predicting on test file\n",
    "y_pred = pd.DataFrame(prediction(df_test),columns=['sentiment']) \n",
    "print(y_pred['sentiment'].value_counts())\n",
    "submission = pd.concat([Id,y_pred['sentiment']],1)\n",
    "submission.to_csv('submission1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
